## ğŸ“š RAG-AI Teaching Assistant:
# A Retrieval-Augmented Generation system that turns your own lecture videos into a personalized AI tutor.


## ğŸš€ Overview:
# RAG-AI Teaching Assistant is a complete pipeline that takes your lecture videos, extracts their audio, transcribes them to structured JSON, converts them into vector embeddings, and finally answers user questions using an LLM with context from your lecture content.

# This lets students and educators build their own AI-powered teaching assistant from scratch â€” on their own data, without manually writing notes.


## ğŸ¯ Key Features:
ğŸ¥ Convert videos â†’ mp3
ğŸ§ Transcribe mp3 â†’ JSON text using Whisper
ğŸ§  Generate vector embeddings from the transcript
ğŸ” Similarity search to find the most relevant chunks
ğŸ’¬ LLM-powered answer generation
ğŸ—‚ï¸ Clean and simple project structure
ğŸ› ï¸ Easy to extend or plug into your app


â”‚
â”œâ”€â”€ video_to_mp3.py          # Convert videos â†’ MP3
|
â”œâ”€â”€ mp3_to_json.py           # Convert MP3 â†’ JSON transcript
|
â”œâ”€â”€ preprocess_json.py       # Create embeddings + save vector store
|
â”œâ”€â”€ process_incoming.py      # Takes user query â†’ returns AI answer
â”‚
â”œâ”€â”€ videos/                  # Place raw lecture videos here
|
â”œâ”€â”€ mp3/                     # Auto-generated MP3 outputs
|
â”œâ”€â”€ json/                    # Auto-generated transcripts
|
â”œâ”€â”€ data/                    # Embeddings, vector store, joblib files
â”‚
â””â”€â”€ Readme.md                # Documentation (this file)


## ğŸ“‚ Project Structure:
# RAG-AI-Teaching-Assistant:
(1) video_to_mp3.py - Convert videos â†’ MP3;

(2) mp3_to_json.py - Convert MP3 â†’ JSON transcript;

(3) preprocess_json.py - Create embeddings + save vector store;

(4) process_incoming.py - Takes user query â†’ returns AI answer;

(5) videos - Place raw lecture videos here;

(6) mp3 - Auto-generated MP3 outputs;

(7) json - Auto-generated transcripts;

(8) data - Embeddings, vector store, joblib files;

(9) Readme.md - Documentation (this file).


## ğŸ§° Tech Stack:
Python 3.10+
OpenAI Whisper â€“ for transcription
Sentence Transformers / Embeddings
Pandas â€“ for DataFrames
Joblib â€“ for saving vector stores
FAISS / Similarity Search (depending on your implementation)
Any LLM API (OpenAI / Groq / others)


## ğŸ› ï¸ Installation:
1ï¸âƒ£ Install dependencies:
pip install -r requirements.txt


## ğŸš¦ How to Use the Project:
# Step 1 â€“ Place your lecture videos
Put all your videos inside the videos/ folder.
videos/
   â”œâ”€â”€ Lecture1.mp4
   â”œâ”€â”€ Lecture2.mkv
   â””â”€â”€ ...

# Step 2 â€“ Convert Videos â†’ MP3
Run: python video_to_mp3.py
This creates:
mp3/
   â”œâ”€â”€ Lecture1.mp3
   â”œâ”€â”€ Lecture2.mp3

# Step 3 â€“ Convert MP3 â†’ JSON Transcripts
Run: python mp3_to_json.py
This generates:
json/
   â”œâ”€â”€ Lecture1.json
   â”œâ”€â”€ Lecture2.json

# Step 4 â€“ Preprocess JSON â†’ Embeddings & Vector Store
Run: python preprocess_json.py
This script will:
Combine all JSONs â†’ DataFrame
Generate embeddings
Save them to a .joblib file

Output saved inside:
data/
   â”œâ”€â”€ embeddings.joblib
   â””â”€â”€ dataframe.pkl

# Step 5 â€“ Question Answering (RAG)
Now query the teaching assistant:
python process_incoming.py "Explain SQL indexes"

The system:
Loads embeddings
Finds the most relevant chunks
Builds a contextual prompt
Sends to your LLM
Returns a detailed answer


## ğŸ§  How the RAG Pipeline Works:
# ğŸ¥ Video â†’ ğŸ”Š Audio â†’ âœï¸ Transcript â†’ ğŸ”¢ Embeddings â†’ ğŸ” Search â†’ ğŸ¤– Answer
Flow:
1) Extract audio
2) Transcribe audio
3) Split + clean text
4) Create embeddings
5) Store embeddings
6) Query via cosine similarity
7) Combine top chunks with the question
8) Feed into the LLM
9) Return contextual answer


## ğŸ“Œ Example Prompt:
python process_incoming.py "What is Flexbox? Explain like I am a beginner."

# output example:
Flexbox is a CSS layout system that helps you arrange items in a row or column without fighting with margins and positioning.


## ğŸŒŸ Future Improvements:
Add UI (Streamlit / Flask)
Add PDF support
Add chunk summaries
Add GPU acceleration for faster Whisper processing
Add vector store options (FAISS, ChromaDB)


## ğŸ¤ Contributing:
Pull requests are welcome!
Feel free to fork the repo and improve any stage of the pipeline.


## ğŸ›¡ï¸ License:
MIT License.



